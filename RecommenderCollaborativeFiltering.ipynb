{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d104d096-4691-46b6-b5d3-1d1d47530e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./MLSpe_venv/lib/python3.13/site-packages (2.3.5)\n",
      "Requirement already satisfied: matplotlib in ./MLSpe_venv/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: tensorflow in ./MLSpe_venv/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./MLSpe_venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./MLSpe_venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./MLSpe_venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./MLSpe_venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./MLSpe_venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./MLSpe_venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./MLSpe_venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./MLSpe_venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in ./MLSpe_venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./MLSpe_venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./MLSpe_venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./MLSpe_venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./MLSpe_venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./MLSpe_venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "076a2e14-9794-4127-9b1a-b5a253c0f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olaoluadisa/Documents/WEBDEV1/webdev/code files/codefiles/MLspecial/MLSpe_venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846e01f3-3e12-46c1-a7c5-f19380f58e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" The original dataset has 9000 movies rated by 600 users. The dataset has been reduced in size to focus on movies from the years since 2000. This dataset consists of ratings on a scale of 0.5 to 5 in 0.5 step increments. The reduced dataset has  ð‘›ð‘¢=443\n",
    "  users, and  ð‘›ð‘š=4778 movies. Below, you will load the movie dataset into the variables  ð‘Œ and  ð‘….\n",
    "\n",
    "The matrix  ð‘Œ (a  ð‘›ð‘šÃ—ð‘›ð‘¢ matrix) stores the ratings  ð‘¦(ð‘–,ð‘—). The matrix  ð‘… is an binary-valued indicator matrix, where  ð‘…(ð‘–,ð‘—)=1 if user  ð‘— gave a rating to movie  ð‘– , and  ð‘…(ð‘–,ð‘—)=0\n",
    "  otherwise.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Functions to load data\n",
    "\n",
    "def load_precalc_params_small():\n",
    "\n",
    "    file = open('./ColabFiltering/small_movies_X.csv', 'rb')\n",
    "    X = loadtxt(file, delimiter = \",\")\n",
    "\n",
    "    file = open('./ColabFiltering/small_movies_W.csv', 'rb')\n",
    "    W = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "    file = open('./ColabFiltering/small_movies_b.csv', 'rb')\n",
    "    b = loadtxt(file,delimiter = \",\")\n",
    "    b = b.reshape(1,-1)\n",
    "    num_movies, num_features = X.shape\n",
    "    num_users,_ = W.shape\n",
    "    return(X, W, b, num_movies, num_features, num_users)\n",
    "    \n",
    "def load_ratings_small():\n",
    "    file = open('./ColabFiltering/small_movies_Y.csv', 'rb')\n",
    "    Y = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "    file = open('./ColabFiltering/small_movies_R.csv', 'rb')\n",
    "    R = loadtxt(file,delimiter = \",\")\n",
    "    return(Y,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c186236a-ce4b-4752-bd8c-8521bceb1129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n",
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "num_features 10\n",
      "num_movies 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9d117f-f64f-4531-bc48-fcc14144e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 3.400 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e613533-ffd1-4981-be48-60fee5633a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function\n",
    "\n",
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    # 1. Calculate predictions\n",
    "    # X: (num_movies, num_features)\n",
    "    # W.T: (num_features, num_users)\n",
    "    # X @ W.T: (num_movies, num_users) - predicted ratings without bias\n",
    "    # b: (1, num_users) - will be broadcast across num_movies rows\n",
    "    predictions = (X @ W.T) + b\n",
    "\n",
    "    # 2. Calculate the error for only the rated movies\n",
    "    # (predictions - Y) will give error for all movies\n",
    "    # Multiplying by R ensures errors are zero for unrated movies\n",
    "    error_matrix = (predictions - Y) * R\n",
    "\n",
    "    # 3. Calculate the squared error sum (first term of the cost function)\n",
    "    J_prediction_error = 0.5 * np.sum(error_matrix**2)\n",
    "\n",
    "    # 4. Calculate regularization terms\n",
    "    # Regularization for X features\n",
    "    J_reg_X = (lambda_ / 2) * np.sum(X**2)\n",
    "\n",
    "    # Regularization for W user parameters\n",
    "    J_reg_W = (lambda_ / 2) * np.sum(W**2)\n",
    "    \n",
    "    # Regularization for b user biases\n",
    "    #J_reg_b = (lambda_ / 2) * np.sum(b**2)\n",
    "\n",
    "    # 5. Total cost is the sum of prediction error and all regularization terms\n",
    "    J = J_prediction_error + J_reg_X + J_reg_W  # + J_reg_b ommited   \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd381bfc-870f-4041-817e-68308db48bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n"
     ]
    }
   ],
   "source": [
    "# Reduce the data set size so that this runs faster\n",
    "num_users_r = 4\n",
    "num_movies_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_movies_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_movies_r, :num_users_r]\n",
    "R_r = R[:num_movies_r, :num_users_r]\n",
    "\n",
    "# Evaluate cost function\n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba6f08f-af62-4ebe-bcd0-1484fcc68c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deaed17b-28cd-46f7-9742-044a5311d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorized Implementation of Cost Function\n",
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7035ac9e-876e-4ef0-930d-403b4334212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n",
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function\n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ac2f1-d46b-4a30-89e9-cb0e813dbd1c",
   "metadata": {},
   "source": [
    "Train and get new recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d562093-5108-488c-8efd-034d3a7c0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Movie List\n",
    "def load_Movie_List_pd():\n",
    "    \"\"\" returns df with and index of movies in the order they are in in the Y matrix \"\"\"\n",
    "    df = pd.read_csv('./ColabFiltering/small_movie_list.csv', header=0, index_col=0,  delimiter=',', quotechar='\"')\n",
    "    mlist = df[\"title\"].to_list()\n",
    "    return(mlist, df)\n",
    "\n",
    "movieList, movieList_df = load_Movie_List_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ffc13f1-8e8f-488f-acdc-ef073c083719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien Ã  dÃ©clarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n",
    "\n",
    "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
    "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2609] = 2;\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien Ã  dÃ©clarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80464935-e275-44d5-8e79-c2003528fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    Preprocess data by subtracting mean rating for every movie (every row).\n",
    "    Only include real ratings R(i,j)=1.\n",
    "    [Ynorm, Ymean] = normalizeRatings(Y, R) normalized Y so that each movie\n",
    "    has a rating of 0 on average. Unrated moves then have a mean rating (0)\n",
    "    Returns the mean rating in Ymean.\n",
    "    \"\"\"\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return(Ynorm, Ymean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d3a6c4-cfc2-4f1b-825f-d5eb0349a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's add these reviews to  ð‘Œ and  ð‘… and normalize the ratings.\n",
    "\n",
    "# Reload ratings\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "# Add new user ratings to Y \n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "# Add new user indicator matrix to R\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088750e-b93e-4bf5-bd31-5b4f2d553a17",
   "metadata": {},
   "source": [
    "Let's prepare to train the model. Initialize the parameters and select the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "610dcb5f-b280-45a7-ba37-bf1620f0d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476e665-ae5a-48db-9221-fbed2c418446",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa782bde-6c94-43e4-a092-dc560e1dd2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2321191.3\n",
      "Training loss at iteration 20: 136169.3\n",
      "Training loss at iteration 40: 51863.7\n",
      "Training loss at iteration 60: 24599.0\n",
      "Training loss at iteration 80: 13630.6\n",
      "Training loss at iteration 100: 8487.7\n",
      "Training loss at iteration 120: 5807.8\n",
      "Training loss at iteration 140: 4311.6\n",
      "Training loss at iteration 160: 3435.3\n",
      "Training loss at iteration 180: 2902.1\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlowâ€™s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adccf345-6cab-4064-9543-1d1bdab2efca",
   "metadata": {},
   "source": [
    "Make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f4c44e-ca33-4a04-801c-19fd575ed2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.49 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
      "Predicting rating 4.48 for movie Martin Lawrence Live: Runteldat (2002)\n",
      "Predicting rating 4.48 for movie Memento (2000)\n",
      "Predicting rating 4.47 for movie Delirium (2014)\n",
      "Predicting rating 4.47 for movie Laggies (2014)\n",
      "Predicting rating 4.47 for movie One I Love, The (2014)\n",
      "Predicting rating 4.46 for movie Particle Fever (2013)\n",
      "Predicting rating 4.45 for movie Eichmann (2007)\n",
      "Predicting rating 4.45 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
      "Predicting rating 4.45 for movie Into the Abyss (2011)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.90 for Shrek (2001)\n",
      "Original 5.0, Predicted 4.84 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2.0, Predicted 2.13 for Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001)\n",
      "Original 5.0, Predicted 4.88 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5.0, Predicted 4.87 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3.0, Predicted 3.00 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5.0, Predicted 4.90 for Incredibles, The (2004)\n",
      "Original 2.0, Predicted 2.11 for Persuasion (2007)\n",
      "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
      "Original 3.0, Predicted 3.00 for Inception (2010)\n",
      "Original 1.0, Predicted 1.41 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien Ã  dÃ©clarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b20e5d2-4e21-4251-b1ff-fe6da457c290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>mean rating</th>\n",
       "      <th>number of ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>4.030961</td>\n",
       "      <td>4.252336</td>\n",
       "      <td>107</td>\n",
       "      <td>Departed, The (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3.985281</td>\n",
       "      <td>4.238255</td>\n",
       "      <td>149</td>\n",
       "      <td>Dark Knight, The (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.477798</td>\n",
       "      <td>4.122642</td>\n",
       "      <td>159</td>\n",
       "      <td>Memento (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>4.887054</td>\n",
       "      <td>4.118919</td>\n",
       "      <td>185</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>4.796531</td>\n",
       "      <td>4.109091</td>\n",
       "      <td>55</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.357304</td>\n",
       "      <td>4.021277</td>\n",
       "      <td>188</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>4.004471</td>\n",
       "      <td>4.006494</td>\n",
       "      <td>77</td>\n",
       "      <td>Shaun of the Dead (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>3.980649</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>Hot Fuzz (2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>4.084643</td>\n",
       "      <td>3.993421</td>\n",
       "      <td>76</td>\n",
       "      <td>Dark Knight Rises, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>4.434171</td>\n",
       "      <td>3.989362</td>\n",
       "      <td>47</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>4.289676</td>\n",
       "      <td>3.960993</td>\n",
       "      <td>141</td>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>4.344999</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>81</td>\n",
       "      <td>Casino Royale (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>4.133481</td>\n",
       "      <td>3.943396</td>\n",
       "      <td>53</td>\n",
       "      <td>How to Train Your Dragon (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>4.175743</td>\n",
       "      <td>3.887931</td>\n",
       "      <td>58</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4.135287</td>\n",
       "      <td>3.871212</td>\n",
       "      <td>132</td>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>3.967900</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>69</td>\n",
       "      <td>Avengers, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4.897137</td>\n",
       "      <td>3.867647</td>\n",
       "      <td>170</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3.971892</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>110</td>\n",
       "      <td>Crouching Tiger, Hidden Dragon (Wo hu cang lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>4.898892</td>\n",
       "      <td>3.836000</td>\n",
       "      <td>125</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>4.874936</td>\n",
       "      <td>3.778523</td>\n",
       "      <td>149</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4.843375</td>\n",
       "      <td>3.761682</td>\n",
       "      <td>107</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>4.021778</td>\n",
       "      <td>3.723684</td>\n",
       "      <td>76</td>\n",
       "      <td>X2: X-Men United (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.242986</td>\n",
       "      <td>3.699248</td>\n",
       "      <td>133</td>\n",
       "      <td>X-Men (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4.878342</td>\n",
       "      <td>3.598039</td>\n",
       "      <td>102</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred  mean rating  number of ratings  \\\n",
       "1743  4.030961     4.252336                107   \n",
       "2112  3.985281     4.238255                149   \n",
       "211   4.477798     4.122642                159   \n",
       "929   4.887054     4.118919                185   \n",
       "2700  4.796531     4.109091                 55   \n",
       "653   4.357304     4.021277                188   \n",
       "1122  4.004471     4.006494                 77   \n",
       "1841  3.980649     4.000000                 61   \n",
       "3083  4.084643     3.993421                 76   \n",
       "2804  4.434171     3.989362                 47   \n",
       "773   4.289676     3.960993                141   \n",
       "1771  4.344999     3.944444                 81   \n",
       "2649  4.133481     3.943396                 53   \n",
       "2455  4.175743     3.887931                 58   \n",
       "361   4.135287     3.871212                132   \n",
       "3014  3.967900     3.869565                 69   \n",
       "246   4.897137     3.867647                170   \n",
       "151   3.971892     3.836364                110   \n",
       "1150  4.898892     3.836000                125   \n",
       "793   4.874936     3.778523                149   \n",
       "366   4.843375     3.761682                107   \n",
       "754   4.021778     3.723684                 76   \n",
       "79    4.242986     3.699248                133   \n",
       "622   4.878342     3.598039                102   \n",
       "\n",
       "                                                  title  \n",
       "1743                               Departed, The (2006)  \n",
       "2112                            Dark Knight, The (2008)  \n",
       "211                                      Memento (2000)  \n",
       "929   Lord of the Rings: The Return of the King, The...  \n",
       "2700                                 Toy Story 3 (2010)  \n",
       "653       Lord of the Rings: The Two Towers, The (2002)  \n",
       "1122                           Shaun of the Dead (2004)  \n",
       "1841                                    Hot Fuzz (2007)  \n",
       "3083                      Dark Knight Rises, The (2012)  \n",
       "2804  Harry Potter and the Deathly Hallows: Part 1 (...  \n",
       "773                                 Finding Nemo (2003)  \n",
       "1771                               Casino Royale (2006)  \n",
       "2649                    How to Train Your Dragon (2010)  \n",
       "2455      Harry Potter and the Half-Blood Prince (2009)  \n",
       "361                               Monsters, Inc. (2001)  \n",
       "3014                               Avengers, The (2012)  \n",
       "246                                        Shrek (2001)  \n",
       "151   Crouching Tiger, Hidden Dragon (Wo hu cang lon...  \n",
       "1150                            Incredibles, The (2004)  \n",
       "793   Pirates of the Caribbean: The Curse of the Bla...  \n",
       "366   Harry Potter and the Sorcerer's Stone (a.k.a. ...  \n",
       "754                             X2: X-Men United (2003)  \n",
       "79                                         X-Men (2000)  \n",
       "622      Harry Potter and the Chamber of Secrets (2002)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can augment the above by selecting from those top movies, movies that have high average ratings and movies with more than 20 ratings\n",
    "\n",
    "filter=(movieList_df[\"number of ratings\"] > 20)\n",
    "movieList_df[\"pred\"] = my_predictions\n",
    "movieList_df = movieList_df.reindex(columns=[\"pred\", \"mean rating\", \"number of ratings\", \"title\"])\n",
    "movieList_df.loc[ix[:300]].loc[filter].sort_values(\"mean rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c04e0-fff5-4000-8e85-d590002a4775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
